import os
import cv2
import numpy as np
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Flatten, Dense
from sklearn.model_selection import train_test_split

# Path to dataset
path = "dogcat"
images = []
classno = []

# Load dataset
mylist = os.listdir(path)
print("Classes found:", mylist)
noofclasses = len(mylist)

for x in mylist:  # Iterate through folder names directly
    folder_path = os.path.join(path, x)
    if os.path.isdir(folder_path):  # Check if it is a directory
        mypiclist = os.listdir(folder_path)
        for y in mypiclist:
            img_path = os.path.join(folder_path, y)
            curimg = cv2.imread(img_path)
            curimg = cv2.resize(curimg, (128, 128))  # Resize to match model input
            images.append(curimg)
            classno.append(mylist.index(x))  # Use index of the folder as the class ID

# Convert to numpy arrays
images = np.array(images)
classno = np.array(classno)
print("Images shape:", images.shape)
print("Labels shape:", classno.shape)

# Train-test split
x_train, x_test, y_train, y_test = train_test_split(images, classno, test_size=0.2, random_state=42)
x_train, x_validation, y_train, y_validation = train_test_split(x_train, y_train, test_size=0.2, random_state=42)
print("Training set shape:", x_train.shape)
print("Validation set shape:", x_validation.shape)
print("Test set shape:", x_test.shape)

# Normalize data
x_train = x_train / 255.0
x_test = x_test / 255.0
x_validation = x_validation / 255.0

# Data Augmentation
datagen = ImageDataGenerator(width_shift_range=0.1, height_shift_range=0.1, zoom_range=0.2, rotation_range=10)
datagen.fit(x_train)

# One-hot encode labels
y_train = to_categorical(y_train, noofclasses)
y_test = to_categorical(y_test, noofclasses)
y_validation = to_categorical(y_validation, noofclasses)

# Model Definition
def mymodel():
    model = Sequential()
    model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(128, 128, 3)))
    model.add(MaxPooling2D(pool_size=(2, 2)))
    model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))
    model.add(Flatten())
    model.add(Dense(128, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(64, activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(noofclasses, activation='softmax'))  # Use softmax for multi-class classification
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    return model

model = mymodel()
print(model.summary())

# Train the model
history = model.fit(
    datagen.flow(x_train, y_train, batch_size=50),
    steps_per_epoch=len(x_train) // 50,
    epochs=10,
    validation_data=(x_validation, y_validation)
)

# Plot loss and accuracy
plt.figure(1)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], label='Validation Loss')
plt.legend()
plt.title('Loss')
plt.show()

plt.figure(2)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.legend()
plt.title('Accuracy')
plt.show()
